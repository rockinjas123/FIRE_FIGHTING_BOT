# importing the required libraries
import os
import cv2
import numpy as np
import time

weights_path = "yolo-coco/yolov3.weights"  #loading weights
config_path = "yolo-coco/yolov3.cfg"     #loading config file
net = cv2.dnn.readNet(weights_path,config_path)  # detecting the neural network
model = cv2.dnn_DetectionModel(net)    # detecting the model
model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)
print("[Info]...Model loading done")

class_name=[]  #making empty list of classes
with open("yolo-coco/coco.names",'r') as file:  #reading classes from the coco.names file(80 classes)
    class_name=file.read().splitlines()
print(class_name)    

Conf_threshold = 0.4
NMS_threshold = 0.4
COLORS = [(0, 255, 0), (0, 0, 255), (255, 0, 0), (255, 255, 0), (255, 0, 255), (0, 255, 255)]  #colours for various boxes
font=cv2.FONT_HERSHEY_COMPLEX     # our font

cap=cv2.VideoCapture(0)

frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
size = (frame_width, frame_height)
    # Below VideoWriter object will create a frame of above defined The output is stored in 'filename.avi' file.
result = cv2.VideoWriter('outputs/output_demo_'+'.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)
    #starting_time = time.time()  # used for sowing the frame processing per sec
    #frame_counter = 0         # used for sowing the frame processing per sec
while True:
    ret, frame = cap.read()
        #frame_counter += 1     # used for sowing the frame processing per sec
    if ret == False:
        break
    classes, scores, boxes = model.detect(frame, Conf_threshold, NMS_threshold)  #checking for classes, their probability, and the boxes
    for (classid, score, box) in zip(classes, scores, boxes):
        color = COLORS[int(classid) % len(COLORS)]    # choosing the colour for box
        label = "%s : %f" % (class_name[classid[0]], score)   # the category with percentage
        cv2.rectangle(frame, box, color, 1)   # drawing a rectangle around object
        cv2.putText(frame, label, (box[0], box[1]-10),font, 0.3, color, 1) # Putting the category
        #endingTime = time.time() - starting_time  # used for sowing the frame processing per sec
        #fps = frame_counter/endingTime    # used for sowing the frame processing per sec
        # print(fps)       # used for sowing the frame processing per sec
        #cv2.putText(frame, f'FPS: {fps}', (20, 50),font, 0.7, (0, 255, 0), 2)
    cv2.imshow('frame', frame)
    result.write(frame)
    key = cv2.waitKey(1)
    if key == ord('q'):
        break
cap.release()
result.release()
cv2.destroyAllWindows()
